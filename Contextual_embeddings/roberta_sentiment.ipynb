{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3d1942",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install gdown transformers datasets tensorflow scikit-learn tf-keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c78b836",
   "metadata": {},
   "source": [
    "## Dataset loading options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dee970",
   "metadata": {},
   "source": [
    "From Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf067321",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = \"0Bz8a_Dbh9QhbZVhsUnRWRDhETzA\"\n",
    "output_name = 'amazon_review_full_csv.tar.gz'\n",
    "!gdown --fuzzy https://drive.google.com/uc?id={file_id} -O {output_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5ca0e5",
   "metadata": {},
   "source": [
    "From local storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6f754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "\n",
    "# uploaded = files.upload()\n",
    "# # Assume che il CSV sia il primo file caricato\n",
    "# print(f\"Select train dataset .csv from your local storage:. . .\")\n",
    "# train_data_filename = list(uploaded.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba79991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uploaded = files.upload()\n",
    "# # Assume che il CSV sia il primo file caricato\n",
    "# print(f\"Select test dataset .csv from your local storage:. . .\")\n",
    "# test_data_filename = list(uploaded.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea5673f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "with tarfile.open(output_name, \"r:gz\") as tar:\n",
    "    tar.extractall(\"Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef4ca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -R Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e61bd72",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ce21f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import tf_keras as keras \n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, TFAutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be7c556",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "gpu_name = None\n",
    "if gpus:\n",
    "    details = tf.config.experimental.get_device_details(gpus[0])\n",
    "    gpu_name = details.get('device_name', gpus[0].name)\n",
    "else:\n",
    "    gpu_name = 'CPU'\n",
    "\n",
    "print(gpu_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873a888d",
   "metadata": {},
   "source": [
    "## Model settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dd8615",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME    = \"roberta-base\"\n",
    "BATCH_SIZE    = 32\n",
    "EPOCHS        = 5\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_LABELS    = 2\n",
    "RANDOM_STATE = 42\n",
    "BASE_DIR_STORAGE = '/content/drive/MyDrive/HLT_models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde2bb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_filename = \"./Dataset/amazon_review_full_csv/train.csv\"\n",
    "test_data_filename = \"./Dataset/amazon_review_full_csv/test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dc5d45",
   "metadata": {},
   "source": [
    "## Train dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b1959a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loading dataset from: {train_data_filename}\")\n",
    "\n",
    "df_train = pd.read_csv(\n",
    "    train_data_filename,\n",
    "    header=None,\n",
    "    names=['label', 'title', 'text'],\n",
    "    quotechar='\"',\n",
    "    doublequote=True,\n",
    "    escapechar='\\\\',\n",
    "    engine='python',\n",
    "    encoding='utf-8',\n",
    "    on_bad_lines='skip'  \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba6757c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3d37b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe7de8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e99c9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0bf385",
   "metadata": {},
   "source": [
    "Drop rows with at least a null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e52a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dropna(inplace=True)\n",
    "df_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f542eb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1acb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\n",
    "    test_data_filename,\n",
    "    header=None,\n",
    "    names=['label', 'title', 'text'],\n",
    "    quotechar='\"',\n",
    "    doublequote=True,\n",
    "    escapechar='\\\\',\n",
    "    engine='python',\n",
    "    encoding='utf-8',\n",
    "    on_bad_lines='skip'  \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd19b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81be5993",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1ef4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fc9f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4b09a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b31abf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8eb724",
   "metadata": {},
   "source": [
    "Drop rows with rating '3' from both train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02225547",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train['label'] != 3]\n",
    "df_test = df_test[df_test['label'] != 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17a8952",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823f365e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b915f4af",
   "metadata": {},
   "source": [
    "## Ratings binary mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cb55ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert ratings (1-5) into 3 classes:\n",
    "def map_rating(row):\n",
    "    rating = row['label']\n",
    "    if rating <= 2:\n",
    "        return 0  # negative\n",
    "    else:\n",
    "        return 1  # positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc866e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_mapped = df_train.copy(deep=True)\n",
    "\n",
    "df_train_mapped['sentiment'] = df_train_mapped.apply(map_rating, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089adb71",
   "metadata": {},
   "source": [
    " ### Downsample Balanced Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc56d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2d463c",
   "metadata": {},
   "source": [
    "### Experiment with a subset of 200k samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66065f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "SAMPLE_SIZE = 200_000\n",
    "BASE_DIR_STORAGE = os.path.join(BASE_DIR_STORAGE, f\"{MODEL_NAME}_{SAMPLE_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a180c52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_mapped, _ = train_test_split(\n",
    "    df_train_mapped,\n",
    "    train_size=SAMPLE_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=df_train_mapped['label']\n",
    ")\n",
    "print(f\"Train size: {len(df_train_mapped)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34867a12",
   "metadata": {},
   "source": [
    "Let's check whether classes are balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50abc7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train_mapped['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33edf751",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_mapped.drop(columns=[\"label\"], inplace=True)\n",
    "display(df_train_mapped.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a458df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_mapped['review'] = df_train_mapped['title'].fillna('') + ' ' + df_train_mapped['text'].fillna('')\n",
    "\n",
    "train_samples = df_train_mapped['review']\n",
    "train_labels = df_train_mapped['sentiment'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfcfa47",
   "metadata": {},
   "source": [
    "## NLTK libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c572061f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('popular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad2a4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = train_samples.str.replace('\\n', ' ', regex=False) \n",
    "train_samples = train_samples.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24d71d9",
   "metadata": {},
   "source": [
    "## Setting Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed56545",
   "metadata": {},
   "source": [
    "This approach uses the same tokenizer used during the model `MODEL_NAME` pretraining. This allow to preserve the context and language semantics.\n",
    "\n",
    "`AutoTokenizer` is able to infer automatically the model used.\n",
    "\n",
    "For example we can possible use RobertaTokenizer, but only if we are sure that we'll use RoBERTa model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b68529",
   "metadata": {},
   "source": [
    "## Analyze tokens distribution to choose the best trade-off for MAX_LEN.\n",
    "The idea is to use the 95th percentile to reduce padding and truncate only outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636bcc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "N = len(train_samples)\n",
    "if N < 10_000:\n",
    "    n_samples = N\n",
    "elif N < 100_000:\n",
    "    n_samples = min(N, 5000)\n",
    "else:\n",
    "    n_samples = min(N, 10_000)\n",
    "    \n",
    "\n",
    "#  n_samples are good enough to get a stable estimation of tokens distribution\n",
    "sample_texts = train_samples.sample(n=n_samples, random_state=RANDOM_STATE).tolist()\n",
    "\n",
    "# Tokenizza solo per analisi (senza padding)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "token_lens = [len(tokenizer.tokenize(t)) for t in sample_texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10136de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(token_lens, bins=50)\n",
    "plt.title(\"Distribution length per token\")\n",
    "plt.xlabel(\"Token per review\")\n",
    "plt.ylabel(\"Frequence\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da42b81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Token length stats:\")\n",
    "print(f\"Mean: {np.mean(token_lens):.1f}\")\n",
    "print(f\"95th percentile: {np.percentile(token_lens, 95):.0f}\")\n",
    "print(f\"Max: {np.max(token_lens)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9d96ce",
   "metadata": {},
   "source": [
    "The 95th percentile of tokenized length is around ~200, meaning that 95% of the reviews are shorter than this threshold.\n",
    "\n",
    "To balance memory efficiency and minimize information loss, we set `MAX_LEN = 205`:\n",
    "- This truncates only the top 5% longest reviews (outliers).\n",
    "- It reduces unnecessary padding for the remaining 95% of the data.\n",
    "- It ensures consistent input size for the model without significant loss of content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64141753",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156c674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6eae6b8",
   "metadata": {},
   "source": [
    "### Una-tantum tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6579f4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "texts   = train_samples.tolist()\n",
    "\n",
    "encodings = tokenizer(\n",
    "    texts,\n",
    "    max_length=MAX_LEN,\n",
    "    truncation=True,\n",
    "    padding='do_not_pad',\n",
    "    return_attention_mask=True,\n",
    "   \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3671b3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "drive.mount(\"/content/drive\")         \n",
    "\n",
    "save_dir = \"/content/drive/MyDrive/Tokenization_cache\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# save on disk\n",
    "np.savez_compressed(\n",
    "    os.path.join(save_dir,f\"train_enc_roberta{SAMPLE_SIZE}.npz\"),\n",
    "    ids   = np.array(encodings[\"input_ids\"], dtype=object),\n",
    "    attn  = np.array(encodings[\"attention_mask\"], dtype=object),\n",
    "    label = train_labels\n",
    ")\n",
    "\n",
    "# save on temporary session\n",
    "np.savez_compressed(\n",
    "   f\"train_enc_roberta_{SAMPLE_SIZE}.npz\",\n",
    "    ids   = np.array(encodings[\"input_ids\"], dtype=object),\n",
    "    attn  = np.array(encodings[\"attention_mask\"], dtype=object),\n",
    "    label = train_labels\n",
    ")\n",
    "\n",
    "print(\"Tokenization completed and saved in\", save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25538040",
   "metadata": {},
   "source": [
    "### Load saved indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f92b898",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.load(f\"train_enc_roberta_{SAMPLE_SIZE}.npz\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d100c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    for ids, attentions, labels in zip(d[\"ids\"], d[\"attn\"], d[\"label\"]):\n",
    "        yield {\n",
    "            \"input_ids\":     np.array(ids,  dtype=np.int32),\n",
    "            \"attention_mask\": np.array(attentions, dtype=np.int32)\n",
    "        }, np.int32(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de46d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ds = tf.data.Dataset.from_generator(\n",
    "    generator,\n",
    "    output_signature=(\n",
    "        {\n",
    "            \"input_ids\":      tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "            \"attention_mask\": tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "        },\n",
    "        tf.TensorSpec(shape=(), dtype=tf.int32),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22513875",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(d[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a13916",
   "metadata": {},
   "source": [
    "### Custom encoder to enable dynamic padding. It inserts padding till the max length of the current batch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7115d116",
   "metadata": {},
   "source": [
    "This code is used only for on the fly encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc8a0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# # funzione Python pura: restituisce SOLO tensori, senza dict\n",
    "# def _py_encode(text, label):\n",
    "#     enc = tokenizer(\n",
    "#         text.numpy().decode(),\n",
    "#         truncation=True,\n",
    "#         max_length=MAX_LEN,\n",
    "#         return_attention_mask=True,\n",
    "#     )\n",
    "#     return (                # tuple flat di tre tensor\n",
    "#         tf.constant(enc[\"input_ids\"],      dtype=tf.int32),\n",
    "#         tf.constant(enc[\"attention_mask\"], dtype=tf.int32),\n",
    "#         tf.cast(label, tf.int32),\n",
    "#     )\n",
    "\n",
    "# # wrapper tf → rimappa la tupla in un dict per Keras\n",
    "# def tf_encode(text, label):\n",
    "#     input_ids, attn_mask, lab = tf.py_function(\n",
    "#         _py_encode,\n",
    "#         inp=[text, label],\n",
    "#         Tout=(tf.int32, tf.int32, tf.int32)   # usato per dichiarare a TensorFlow il tipo di ciascun tensore che la funzione Python restituirà.\n",
    "#     )\n",
    "#     # Imposta le shape dinamiche, altrimenti sono <unknown>\n",
    "#     input_ids.set_shape([None])\n",
    "#     attn_mask.set_shape([None])\n",
    "#     lab.set_shape([])\n",
    "\n",
    "#     return {'input_ids': input_ids,\n",
    "#             'attention_mask': attn_mask}, lab\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a8a9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor_dataset = (\n",
    "#     raw_ds\n",
    "#     .map(tf_encode, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "#     .padded_batch(\n",
    "#         BATCH_SIZE,\n",
    "#         padded_shapes=({'input_ids':[None], 'attention_mask':[None]}, []),\n",
    "#         padding_values=({'input_ids': tokenizer.pad_token_id,\n",
    "#                          'attention_mask': 0}, 0),\n",
    "#     )\n",
    "#     .prefetch(tf.data.AUTOTUNE)                       \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0d88b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_dataset = (\n",
    "    raw_ds\n",
    "    .shuffle(N, seed=RANDOM_STATE)\n",
    "    .padded_batch(\n",
    "        BATCH_SIZE,\n",
    "        padded_shapes=({\"input_ids\": [None], \"attention_mask\": [None]}, []),\n",
    "        padding_values=({\"input_ids\": tokenizer.pad_token_id,\n",
    "                         \"attention_mask\": 0}, 0),\n",
    "    )\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c51f5f",
   "metadata": {},
   "source": [
    "Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc54c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = int(0.3 * N)\n",
    "val_size  = int(0.2 * N)\n",
    "train_size = N - test_size - val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0289b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train size:\", train_size)\n",
    "print(\"Val   size:\", val_size)\n",
    "print(\"Test  size:\", test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3f46c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled = raw_ds.shuffle(buffer_size=N, seed=RANDOM_STATE, reshuffle_each_iteration=False)\n",
    "\n",
    "test_raw   = shuffled.take(test_size)\n",
    "remainder  = shuffled.skip(test_size)\n",
    "val_raw    = remainder.take(val_size)\n",
    "train_raw  = remainder.skip(val_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6289f2",
   "metadata": {},
   "source": [
    "The following function wraps two key steps into one reusable pipeline stage:\n",
    "1. padded_batch(...)\n",
    "\t- Groups elements into batches of size BATCH_SIZE\n",
    "\t- Dynamically pads each batch’s input_ids and attention_mask to the length of the longest sequence in that batch\n",
    "2.\t.prefetch(tf.data.AUTOTUNE)\n",
    "\t- Overlaps data preparation and model execution to keep the GPU fed\n",
    "\n",
    "In short: *prepare(ds)* turns a raw dataset of variable‐length examples into an efficient, dynamically‐padded, batched dataset ready for training.\n",
    "\n",
    "Dynamic padding means that, instead of padding every sequence up to a fixed global MAX_LEN, you pad each batch only up to the length of its longest example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2511380c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(ds, *, shuffle_buffer=None, do_repeat=False):\n",
    "    \"\"\"\n",
    "    Prepares a Dataset that was created with `from_generator` by applying:\n",
    "      - reshuffling (only for training)\n",
    "      - batching with padded_batch (dynamic padding)\n",
    "      - infinite repetition (only for training)\n",
    "      - prefetching for performances\n",
    "\n",
    "    \"\"\"\n",
    "    pipeline = ds\n",
    "\n",
    "    # only for TRAIN: shuffle before each epoch\n",
    "    if shuffle_buffer:\n",
    "        pipeline = pipeline.shuffle(buffer_size=shuffle_buffer, seed=RANDOM_STATE)\n",
    "\n",
    "    # batch + dynamic padding\n",
    "    pipeline = pipeline.padded_batch(\n",
    "        BATCH_SIZE,\n",
    "        padded_shapes=(\n",
    "            {\"input_ids\":      [None],\n",
    "             \"attention_mask\": [None]},\n",
    "            []),\n",
    "        padding_values=(\n",
    "            {\"input_ids\":      tokenizer.pad_token_id,\n",
    "             \"attention_mask\": 0},\n",
    "            0),\n",
    "    )\n",
    "\n",
    "    # in train set, during training without repeat, train set emits all batches only one time\n",
    "    # if steps_for_epochs > real batches -> input ran out of data\n",
    "    # with epochs > 1, at the second epoch there is nothing to read \n",
    "    if do_repeat:\n",
    "        pipeline = pipeline.repeat()\n",
    "\n",
    "    # prefetch per overlap CPU/GPU\n",
    "    return pipeline.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861c44b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = prepare(train_raw,\n",
    "                        shuffle_buffer=train_size,  # shuffle for each epoch\n",
    "                        do_repeat=True)             # repeat\n",
    "val_dataset   = prepare(val_raw,\n",
    "                        shuffle_buffer=None,        # no shuffle for epoch no repeat\n",
    "                        do_repeat=False)   \n",
    "\n",
    "test_dataset = prepare(\n",
    "    test_raw,\n",
    "    shuffle_buffer=None,   \n",
    "    do_repeat=False        \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d04f338",
   "metadata": {},
   "source": [
    "### Checking for Overlap Between Train, Validation, and Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324360bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use a sample of 1000 to check statistically whether the 3 sets have any intersections\n",
    "def sample_hashes(ds, n=1000):\n",
    "    h = set()\n",
    "    for ex, _ in ds.take(n):\n",
    "        h.add(hash(ex[\"input_ids\"].numpy().tobytes()))\n",
    "    return h\n",
    "\n",
    "h_tr = sample_hashes(train_raw)\n",
    "h_va = sample_hashes(val_raw)\n",
    "h_te = sample_hashes(test_raw)\n",
    "\n",
    "print(\"Intersections between Train and Val  :\", len(h_tr & h_va))\n",
    "print(\"Intersection between Train and Test :\", len(h_tr & h_te))\n",
    "print(\"Intersections between Val and Test :\", len(h_va & h_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665183b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "steps_per_epoch   = math.ceil(train_size / BATCH_SIZE)\n",
    "validation_steps  = math.ceil(val_size   / BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f58efbc",
   "metadata": {},
   "source": [
    "## Choose whether retrain encoder or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b9908b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER_TRAINABLE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220f081a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cae28d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFRobertaModel\n",
    "encoder = TFRobertaModel.from_pretrained(MODEL_NAME)\n",
    "encoder.trainable = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcc5b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids      = keras.Input(shape=(None,), dtype=\"int32\", name=\"input_ids\")\n",
    "attention_mask = keras.Input(shape=(None,), dtype=\"int32\", name=\"attention_mask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097b815a",
   "metadata": {},
   "source": [
    "Link to pretrained encoders info: https://huggingface.co/transformers/v2.4.0/pretrained_models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7862965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# executed for each batch\n",
    "# here roberta converts input_ids into embedding vectors (batch_size, seq_len, hidden_size) where hidden_size = 768 for roberta-base.\n",
    "encoder_outputs = encoder({'input_ids': input_ids, 'attention_mask': attention_mask}, training = True)\n",
    "pooled_output = encoder_outputs.pooler_output\n",
    "\n",
    "# last hidden state is a tensor (batch_size, seq_len, hidden_size) containing the contextual representation of each token.\n",
    "# cls is used to represent the entire sentence\n",
    "# hidden_states = encoder_outputs.last_hidden_state\n",
    "# cls_token = hidden_states[:, 0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d54a28f",
   "metadata": {},
   "source": [
    "### Building Classification Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6640343",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_keras.layers import LayerNormalization\n",
    "\n",
    "x = keras.layers.Dense(256, activation='relu', name='dense_relu')(pooled_output)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "x = keras.layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "\n",
    "logits = keras.layers.Dense(1, name='logits')(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9947bb38",
   "metadata": {},
   "source": [
    "### Entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a936fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=[input_ids, attention_mask], outputs=logits)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421c3327",
   "metadata": {},
   "source": [
    "Check that encoder parameters are not retrainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733a583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(f\"{layer.name:25s}  trainable={layer.trainable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5b0456",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_opt = keras.optimizers.AdamW(           # da tensorflow-addons\n",
    "    learning_rate = LEARNING_RATE,\n",
    "    weight_decay  = 1e-2,\n",
    "    epsilon       = 1e-8,\n",
    "    clipnorm      = 1.0,\n",
    "\n",
    ")\n",
    "\n",
    "optimizer = keras.mixed_precision.LossScaleOptimizer(base_opt)\n",
    "loss= keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[keras.metrics.BinaryAccuracy(name=\"accuracy\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80c2b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ed0b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',        \n",
    "    patience=2,                \n",
    "    restore_best_weights=True, \n",
    "    verbose=1                 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3bff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data= val_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stop] ,\n",
    "    validation_steps=validation_steps,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21f469e",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "elapsed = end_time - start_time\n",
    "\n",
    "print(f\"Total training time: {elapsed:.1f} s ({elapsed/60:.2f} min)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e7afe7",
   "metadata": {},
   "source": [
    "### Training History plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09021103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Estrai le liste di loss dal history\n",
    "train_loss = history.history['loss']\n",
    "val_loss   = history.history['val_loss']\n",
    "epochs     = range(1, len(train_loss) + 1)\n",
    "\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc   = history.history['val_accuracy']\n",
    "\n",
    "\n",
    "# Disegna il plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(epochs, train_loss, marker='o', label='Train Loss')\n",
    "plt.plot(epochs, val_loss,   marker='o', label='Validation Loss')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.xticks(epochs)           # mostra tutte le epoche sull'asse x\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(epochs, train_acc, marker='o', label='Train Accuracy')\n",
    "plt.plot(epochs, val_acc,   marker='o', label='Validation Accuracy')\n",
    "plt.title('Training vs Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(epochs)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd1ab7f",
   "metadata": {},
   "source": [
    "## Model evaluation with Internal test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e74c883",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.concatenate([y for x, y in test_dataset], axis=0)\n",
    "\n",
    "pred_logits = model.predict(test_dataset)\n",
    "pred_probs  = tf.sigmoid(pred_logits).numpy().ravel()\n",
    "pred_labels = (pred_probs >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccac3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "test_acc = accuracy_score(y_true, pred_labels)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998c2e4b",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97121a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "conf_matrix = confusion_matrix(y_true, pred_labels)\n",
    "\n",
    "# 4. Plot it\n",
    "fig, ax = plt.subplots()\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\n",
    "disp.plot(ax=ax)\n",
    "ax.set_title(\"Confusion Matrix on Internal Test Set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a357759f",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7b4001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, json, os\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "\n",
    "os.makedirs(BASE_DIR_STORAGE, exist_ok=True)\n",
    "\n",
    "file = os.path.join(BASE_DIR_STORAGE, f'roberta_{SAMPLE_SIZE}.keras')\n",
    "\n",
    "\n",
    "model.save(file)\n",
    "tokenizer.save_pretrained(BASE_DIR_STORAGE)\n",
    "\n",
    "metadata = {\n",
    "    \"timestamp\":          time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"total_training_time_s\": round(elapsed, 1),\n",
    "    \"num_samples\":           SAMPLE_SIZE,\n",
    "    \"train_size\":            train_size,\n",
    "    \"val_size\":              val_size,\n",
    "    \"internal_test_size\":    test_size,\n",
    "    \"batch_size\":            BATCH_SIZE,\n",
    "    \"epochs\":                EPOCHS,\n",
    "    \"encoder_trainable\":     ENCODER_TRAINABLE,\n",
    "    \"history\":               history.history,  \n",
    "    \"gpu\": gpu_name,\n",
    "    \"internal_test_accuracy\": test_acc,\n",
    "    \n",
    "}\n",
    "\n",
    "with open(os.path.join(BASE_DIR_STORAGE, f'training_metadata_roberta_{SAMPLE_SIZE}.json'), 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"Saved model + tokenizer + metadata in {BASE_DIR_STORAGE}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
