{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3d1942",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install gdown transformers datasets tensorflow scikit-learn tf-keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c78b836",
   "metadata": {},
   "source": [
    "## Dataset loading options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dee970",
   "metadata": {},
   "source": [
    "From Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf067321",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = \"0Bz8a_Dbh9QhbZVhsUnRWRDhETzA\"\n",
    "output_name = 'amazon_review_full_csv.tar.gz'\n",
    "!gdown --fuzzy https://drive.google.com/uc?id={file_id} -O {output_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5ca0e5",
   "metadata": {},
   "source": [
    "From local storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6f754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "\n",
    "# uploaded = files.upload()\n",
    "# # Assume che il CSV sia il primo file caricato\n",
    "# print(f\"Select train dataset .csv from your local storage:. . .\")\n",
    "# train_data_filename = list(uploaded.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba79991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uploaded = files.upload()\n",
    "# # Assume che il CSV sia il primo file caricato\n",
    "# print(f\"Select test dataset .csv from your local storage:. . .\")\n",
    "# test_data_filename = list(uploaded.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea5673f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "with tarfile.open(output_name, \"r:gz\") as tar:\n",
    "    tar.extractall(\"Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef4ca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -R Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e61bd72",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ce21f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import tf_keras as keras \n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, TFAutoModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873a888d",
   "metadata": {},
   "source": [
    "## Model settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dd8615",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME    = \"roberta-base\"\n",
    "BATCH_SIZE    = 32\n",
    "EPOCHS        = 5\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_LABELS    = 2\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde2bb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_filename = \"./Dataset/amazon_review_full_csv/train.csv\"\n",
    "test_data_filename = \"./Dataset/amazon_review_full_csv/test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dc5d45",
   "metadata": {},
   "source": [
    "## Train dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "85b1959a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from: ../Dataset/amazon_review_full_csv/train.csv\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading dataset from: {train_data_filename}\")\n",
    "\n",
    "df_train = pd.read_csv(\n",
    "    train_data_filename,\n",
    "    header=None,\n",
    "    names=['label', 'title', 'text'],\n",
    "    quotechar='\"',\n",
    "    doublequote=True,\n",
    "    escapechar='\\\\',\n",
    "    engine='python',\n",
    "    encoding='utf-8',\n",
    "    on_bad_lines='skip'  \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aba6757c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2999746"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3b3d37b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.999746e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.000022e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.414218e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label\n",
       "count  2.999746e+06\n",
       "mean   3.000022e+00\n",
       "std    1.414218e+00\n",
       "min    1.000000e+00\n",
       "25%    2.000000e+00\n",
       "50%    3.000000e+00\n",
       "75%    4.000000e+00\n",
       "max    5.000000e+00"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "abe7de8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>more like funchuck</td>\n",
       "      <td>Gave this to my dad for a gag gift after direc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Inspiring</td>\n",
       "      <td>I hope a lot of people hear this cd. We need m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>The best soundtrack ever to anything.</td>\n",
       "      <td>I'm reading a lot of reviews saying that this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Chrono Cross OST</td>\n",
       "      <td>The music of Yasunori Misuda is without questi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Too good to be true</td>\n",
       "      <td>Probably the greatest soundtrack in history! U...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                  title  \\\n",
       "0      3                     more like funchuck   \n",
       "1      5                              Inspiring   \n",
       "2      5  The best soundtrack ever to anything.   \n",
       "3      4                       Chrono Cross OST   \n",
       "4      5                    Too good to be true   \n",
       "\n",
       "                                                text  \n",
       "0  Gave this to my dad for a gag gift after direc...  \n",
       "1  I hope a lot of people hear this cd. We need m...  \n",
       "2  I'm reading a lot of reviews saying that this ...  \n",
       "3  The music of Yasunori Misuda is without questi...  \n",
       "4  Probably the greatest soundtrack in history! U...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6e99c9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "title    188\n",
       "text       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0bf385",
   "metadata": {},
   "source": [
    "Drop rows with at least a null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f7e52a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2999558"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dropna(inplace=True)\n",
    "df_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f542eb76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label    0\n",
       "title    0\n",
       "text     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ab1acb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\n",
    "    test_data_filename,\n",
    "    header=None,\n",
    "    names=['label', 'title', 'text'],\n",
    "    quotechar='\"',\n",
    "    doublequote=True,\n",
    "    escapechar='\\\\',\n",
    "    engine='python',\n",
    "    encoding='utf-8',\n",
    "    on_bad_lines='skip'  \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8bd19b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>649954.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.414217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               label\n",
       "count  649954.000000\n",
       "mean        3.000011\n",
       "std         1.414217\n",
       "min         1.000000\n",
       "25%         2.000000\n",
       "50%         3.000000\n",
       "75%         4.000000\n",
       "max         5.000000"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "81be5993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "649954"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0d1ef4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label     0\n",
       "title    26\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "88fc9f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5d4b09a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label    0\n",
       "title    0\n",
       "text     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1b31abf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "649928"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8eb724",
   "metadata": {},
   "source": [
    "Drop rows with rating '3' from both train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "02225547",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train['label'] != 3]\n",
    "df_test = df_test[df_test['label'] != 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d17a8952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2399666"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "823f365e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "519942"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b915f4af",
   "metadata": {},
   "source": [
    "## Ratings binary mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "81cb55ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert ratings (1-5) into 3 classes:\n",
    "def map_rating(row):\n",
    "    rating = row['label']\n",
    "    if rating <= 2:\n",
    "        return 0  # negative\n",
    "    else:\n",
    "        return 1  # positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fc866e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_mapped = df_train.copy(deep=True)\n",
    "\n",
    "df_train_mapped['sentiment'] = df_train_mapped.apply(map_rating, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089adb71",
   "metadata": {},
   "source": [
    " ### Downsample Balanced Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "efc56d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2d463c",
   "metadata": {},
   "source": [
    "### Experiment with a trainset of 1k samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66065f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a180c52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 100000\n"
     ]
    }
   ],
   "source": [
    "df_train_mapped, _ = train_test_split(\n",
    "    df_train_mapped,\n",
    "    train_size=SAMPLE_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=df_train_mapped['label']\n",
    ")\n",
    "print(f\"Train size: {len(df_train_mapped)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34867a12",
   "metadata": {},
   "source": [
    "Let's check whether classes are balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "50abc7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "5    25001\n",
      "4    25001\n",
      "2    24999\n",
      "1    24999\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_train_mapped['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "33edf751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2281053</th>\n",
       "      <td>Great Game</td>\n",
       "      <td>I purchased this as a gift for my brother and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535186</th>\n",
       "      <td>Grainy and blocky</td>\n",
       "      <td>The movie was good, its the video compression ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942601</th>\n",
       "      <td>doesn't even deserve 1 star</td>\n",
       "      <td>This is the worst horror movie ever written..V...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523608</th>\n",
       "      <td>semi scholarship</td>\n",
       "      <td>Although based on the premise of a real book o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081248</th>\n",
       "      <td>It doesn&amp;#65533;t make you cool to dislike thi...</td>\n",
       "      <td>If you genuinely don't like this movie, I unde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     title  \\\n",
       "2281053                                         Great Game   \n",
       "1535186                                  Grainy and blocky   \n",
       "942601                         doesn't even deserve 1 star   \n",
       "1523608                                   semi scholarship   \n",
       "1081248  It doesn&#65533;t make you cool to dislike thi...   \n",
       "\n",
       "                                                      text  sentiment  \n",
       "2281053  I purchased this as a gift for my brother and ...          1  \n",
       "1535186  The movie was good, its the video compression ...          0  \n",
       "942601   This is the worst horror movie ever written..V...          0  \n",
       "1523608  Although based on the premise of a real book o...          0  \n",
       "1081248  If you genuinely don't like this movie, I unde...          1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train_mapped.drop(columns=[\"label\"], inplace=True)\n",
    "display(df_train_mapped.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e9a458df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_mapped['review'] = df_train_mapped['title'].fillna('') + ' ' + df_train_mapped['text'].fillna('')\n",
    "\n",
    "train_samples = df_train_mapped['review']\n",
    "train_labels = df_train_mapped['sentiment'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfcfa47",
   "metadata": {},
   "source": [
    "## NLTK libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c572061f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/lorisgiunta/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/lorisgiunta/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /Users/lorisgiunta/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /Users/lorisgiunta/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /Users/lorisgiunta/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /Users/lorisgiunta/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /Users/lorisgiunta/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /Users/lorisgiunta/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /Users/lorisgiunta/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /Users/lorisgiunta/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /Users/lorisgiunta/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /Users/lorisgiunta/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /Users/lorisgiunta/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     /Users/lorisgiunta/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     /Users/lorisgiunta/nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /Users/lorisgiunta/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     /Users/lorisgiunta/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     /Users/lorisgiunta/nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /Users/lorisgiunta/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /Users/lorisgiunta/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /Users/lorisgiunta/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /Users/lorisgiunta/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /Users/lorisgiunta/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /Users/lorisgiunta/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('popular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4ad2a4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = train_samples.str.replace('\\n', ' ', regex=False) \n",
    "train_samples = train_samples.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24d71d9",
   "metadata": {},
   "source": [
    "## Setting Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed56545",
   "metadata": {},
   "source": [
    "This approach uses the same tokenizer used during the model `MODEL_NAME` pretraining. This allow to preserve the context and language semantics.\n",
    "\n",
    "`AutoTokenizer` is able to infer automatically the model used.\n",
    "\n",
    "For example we can possible use RobertaTokenizer, but only if we are sure that we'll use RoBERTa model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b68529",
   "metadata": {},
   "source": [
    "## Analyze tokens distribution to choose the best trade-off for MAX_LEN.\n",
    "The idea is to use the 95th percentile to reduce padding and truncate only outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636bcc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 50000 samples are good enough to get a stable estimation of tokens distribution\n",
    "sample_texts = train_samples.sample(n=2000, random_state=RANDOM_STATE).tolist()\n",
    "\n",
    "# Tokenizza solo per analisi (senza padding)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "token_lens = [len(tokenizer.tokenize(t)) for t in sample_texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "10136de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(token_lens, bins=50)\n",
    "plt.title(\"Distribution length per token\")\n",
    "plt.xlabel(\"Token per review\")\n",
    "plt.ylabel(\"Frequence\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "da42b81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token length stats:\n",
      "Mean: 98.8\n",
      "95th percentile: 203\n",
      "Max: 335\n"
     ]
    }
   ],
   "source": [
    "print(\"Token length stats:\")\n",
    "print(f\"Mean: {np.mean(token_lens):.1f}\")\n",
    "print(f\"95th percentile: {np.percentile(token_lens, 95):.0f}\")\n",
    "print(f\"Max: {np.max(token_lens)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9d96ce",
   "metadata": {},
   "source": [
    "The 95th percentile of tokenized length is around ~200, meaning that 95% of the reviews are shorter than this threshold.\n",
    "\n",
    "To balance memory efficiency and minimize information loss, we set `MAX_LEN = 205`:\n",
    "- This truncates only the top 5% longest reviews (outliers).\n",
    "- It reduces unnecessary padding for the remaining 95% of the data.\n",
    "- It ensures consistent input size for the model without significant loss of content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64141753",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "156c674e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000,)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6eae6b8",
   "metadata": {},
   "source": [
    "### Una-tantum tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6579f4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "texts   = train_samples.tolist()\n",
    "\n",
    "encodings = tokenizer(\n",
    "    texts,\n",
    "    max_length=MAX_LEN,\n",
    "    truncation=True,\n",
    "    padding='do_not_pad',\n",
    "    return_attention_mask=True,\n",
    "   \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3671b3bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      3\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m\"\u001b[39m)         \n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "# drive.mount(\"/content/drive\")         \n",
    "\n",
    "# save_dir = \"/content/drive/MyDrive/Tokenization_cache\"\n",
    "# os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# # save on disk\n",
    "# np.savez_compressed(\n",
    "#     os.path.join(save_dir,\"train_enc_roberta_30k.npz\"),\n",
    "#     ids   = np.array(encodings[\"input_ids\"], dtype=object),\n",
    "#     attn  = np.array(encodings[\"attention_mask\"], dtype=object),\n",
    "#     label = train_labels\n",
    "# )\n",
    "\n",
    "# save on temporary session\n",
    "np.savez_compressed(\n",
    "   \"train_enc_roberta_30k.npz\",\n",
    "    ids   = np.array(encodings[\"input_ids\"], dtype=object),\n",
    "    attn  = np.array(encodings[\"attention_mask\"], dtype=object),\n",
    "    label = train_labels\n",
    ")\n",
    "\n",
    "# print(\"Tokenization completed and saved in\", save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25538040",
   "metadata": {},
   "source": [
    "### Load saved indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9087fd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.load(\"train_enc_roberta_30k.npz\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d100c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    for ids, attentions, labels in zip(d[\"ids\"], d[\"attn\"], d[\"label\"]):\n",
    "        yield {\n",
    "            \"input_ids\":     np.array(ids,  dtype=np.int32),\n",
    "            \"attention_mask\": np.array(attentions, dtype=np.int32)\n",
    "        }, np.int32(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de46d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ds = tf.data.Dataset.from_generator(\n",
    "    generator,\n",
    "    output_signature=(\n",
    "        {\n",
    "            \"input_ids\":      tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "            \"attention_mask\": tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "        },\n",
    "        tf.TensorSpec(shape=(), dtype=tf.int32),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a13916",
   "metadata": {},
   "source": [
    "### Custom encoder to enable dynamic padding. It inserts padding till the max length of the current batch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7115d116",
   "metadata": {},
   "source": [
    "This code is used only for on the fly encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc8a0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# # funzione Python pura: restituisce SOLO tensori, senza dict\n",
    "# def _py_encode(text, label):\n",
    "#     enc = tokenizer(\n",
    "#         text.numpy().decode(),\n",
    "#         truncation=True,\n",
    "#         max_length=MAX_LEN,\n",
    "#         return_attention_mask=True,\n",
    "#     )\n",
    "#     return (                # tuple flat di tre tensor\n",
    "#         tf.constant(enc[\"input_ids\"],      dtype=tf.int32),\n",
    "#         tf.constant(enc[\"attention_mask\"], dtype=tf.int32),\n",
    "#         tf.cast(label, tf.int32),\n",
    "#     )\n",
    "\n",
    "# # wrapper tf  rimappa la tupla in un dict per Keras\n",
    "# def tf_encode(text, label):\n",
    "#     input_ids, attn_mask, lab = tf.py_function(\n",
    "#         _py_encode,\n",
    "#         inp=[text, label],\n",
    "#         Tout=(tf.int32, tf.int32, tf.int32)   # usato per dichiarare a TensorFlow il tipo di ciascun tensore che la funzione Python restituir.\n",
    "#     )\n",
    "#     # Imposta le shape dinamiche, altrimenti sono <unknown>\n",
    "#     input_ids.set_shape([None])\n",
    "#     attn_mask.set_shape([None])\n",
    "#     lab.set_shape([])\n",
    "\n",
    "#     return {'input_ids': input_ids,\n",
    "#             'attention_mask': attn_mask}, lab\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a8a9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor_dataset = (\n",
    "#     raw_ds\n",
    "#     .map(tf_encode, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "#     .padded_batch(\n",
    "#         BATCH_SIZE,\n",
    "#         padded_shapes=({'input_ids':[None], 'attention_mask':[None]}, []),\n",
    "#         padding_values=({'input_ids': tokenizer.pad_token_id,\n",
    "#                          'attention_mask': 0}, 0),\n",
    "#     )\n",
    "#     .prefetch(tf.data.AUTOTUNE)                       \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800512b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_dataset = (\n",
    "    raw_ds\n",
    "    .shuffle(len(d[\"label\"]), seed=RANDOM_STATE)\n",
    "    .padded_batch(\n",
    "        BATCH_SIZE,\n",
    "        padded_shapes=({'input_ids':[None], 'attention_mask':[None]}, []),\n",
    "        padding_values=({'input_ids': tokenizer.pad_token_id,\n",
    "                         'attention_mask': 0}, 0),\n",
    "    )\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf250613",
   "metadata": {},
   "source": [
    "## Choose whether retrain encoder or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9ceee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER_TRAINABLE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87de259",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ed4ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.layer_norm.weight', 'roberta.embeddings.position_ids', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFRobertaModel\n",
    "encoder = TFRobertaModel.from_pretrained(MODEL_NAME)\n",
    "encoder.trainable = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aa6b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids      = keras.Input(shape=(None,), dtype=\"int32\", name=\"input_ids\")\n",
    "attention_mask = keras.Input(shape=(None,), dtype=\"int32\", name=\"attention_mask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823fddc6",
   "metadata": {},
   "source": [
    "Link to pretrained encoders info: https://huggingface.co/transformers/v2.4.0/pretrained_models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1884dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# executed for each batch\n",
    "# here roberta converts input_ids into embedding vectors (batch_size, seq_len, hidden_size) where hidden_size = 768 for roberta-base.\n",
    "encoder_outputs = encoder({'input_ids': input_ids, 'attention_mask': attention_mask}, training = True)\n",
    "pooled_output = encoder_outputs.pooler_output\n",
    "\n",
    "# last hidden state is a tensor (batch_size, seq_len, hidden_size) containing the contextual representation of each token.\n",
    "# cls is used to represent the entire sentence\n",
    "# hidden_states = encoder_outputs.last_hidden_state\n",
    "# cls_token = hidden_states[:, 0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff079eb",
   "metadata": {},
   "source": [
    "### Building Classification Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e570ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = keras.layers.Dense(256, activation='relu', name='dense_relu')(pooled_output)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "x = keras.layers.Dense(64, activation='relu')(x)\n",
    "x = keras.layers.LayerNormalization()(x)\n",
    "\n",
    "logits = keras.layers.Dense(NUM_LABELS, name='logits')(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ed55ae",
   "metadata": {},
   "source": [
    "### Entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a69c6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " attention_mask (InputLayer  [(None, 210)]                0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " input_ids (InputLayer)      [(None, 210)]                0         []                            \n",
      "                                                                                                  \n",
      " tf_roberta_model_1 (TFRobe  TFBaseModelOutputWithPooli   1246456   ['attention_mask[0][0]',      \n",
      " rtaModel)                   ngAndCrossAttentions(last_   32         'input_ids[0][0]']           \n",
      "                             hidden_state=(None, 210, 7                                           \n",
      "                             68),                                                                 \n",
      "                              pooler_output=(None, 768)                                           \n",
      "                             , past_key_values=None, hi                                           \n",
      "                             dden_states=None, attentio                                           \n",
      "                             ns=None, cross_attentions=                                           \n",
      "                             None)                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None, 768)                  0         ['tf_roberta_model_1[0][0]']  \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " dense_relu (Dense)          (None, 256)                  196864    ['tf.__operators__.getitem_1[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " logits (Dense)              (None, 2)                    514       ['dense_relu[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 124843010 (476.24 MB)\n",
      "Trainable params: 197378 (771.01 KB)\n",
      "Non-trainable params: 124645632 (475.49 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Model(inputs=[input_ids, attention_mask], outputs=logits)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c83ae9",
   "metadata": {},
   "source": [
    "Check that encoder parameters are not retrainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7a6c81df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_mask             trainable=True\n",
      "input_ids                  trainable=True\n",
      "tf_roberta_model_1         trainable=False\n",
      "tf.__operators__.getitem_1  trainable=True\n",
      "dense_relu                 trainable=True\n",
      "logits                     trainable=True\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(f\"{layer.name:25s}  trainable={layer.trainable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6953b8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_opt = keras.optimizers.AdamW(           # da tensorflow-addons\n",
    "    learning_rate = LEARNING_RATE,\n",
    "    weight_decay  = 1e-2,\n",
    "    epsilon       = 1e-8,\n",
    "    clipnorm      = 1.0,\n",
    "\n",
    ")\n",
    "\n",
    "optimizer = keras.mixed_precision.LossScaleOptimizer(base_opt)\n",
    "loss=  keras.losses.SparseCategoricalCrossentropy(from_logits=True) \n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[\"sparse_categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d854fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_batches = tf.data.experimental.cardinality(tensor_dataset).numpy() \n",
    "val_batches   = int(total_batches * 0.2)               \n",
    "\n",
    "val_dataset   = tensor_dataset.take(val_batches)      \n",
    "train_dataset = tensor_dataset.skip(val_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4305a2d0",
   "metadata": {},
   "source": [
    "Define batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc54c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(d[\"label\"])\n",
    "steps_per_epoch = N // BATCH_SIZE\n",
    "val_size      = int(0.2 * N)\n",
    "val_batches   = val_size // BATCH_SIZE\n",
    "train_batches = (N - val_size) // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c51f5f",
   "metadata": {},
   "source": [
    "Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261b5524",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset   = tensor_dataset.take(val_batches)\n",
    "train_dataset = tensor_dataset.skip(val_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80c2b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ed0b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',        # controlla la loss di validazione\n",
    "    patience=2,                # se non migliora per 2 epoche, interrompe\n",
    "    restore_best_weights=True, # ricarica i pesi migliori visti finora\n",
    "    verbose=1                  # stampa un messaggio quando scatta\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3bff6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  11/5000 [..............................] - ETA: 1:57:49 - loss: 6.4087 - accuracy: 0.4943"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.4/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.4/lib/python3.12/site-packages/tf_keras/src/engine/training.py:1804\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1796\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1797\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1798\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1801\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1802\u001b[0m ):\n\u001b[1;32m   1803\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1804\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1806\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.4/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.4/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.4/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:869\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    868\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 869\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    875\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.4/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.4/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.4/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.4/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.4/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1703\u001b[0m   )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.4/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data= val_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stop] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21f469e",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "elapsed = end_time - start_time\n",
    "\n",
    "print(f\" Total training time: {elapsed:.1f} s ({elapsed/60:.2f} min)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9745017b",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aeb5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, json, os\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "save_path = '/content/drive/HLT_models/roberta-keras-custom'\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "\n",
    "metadata = {\n",
    "    \"timestamp\":          time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"total_training_time_s\": round(elapsed, 1),\n",
    "    \"num_train_samples\":     SAMPLE_SIZE,\n",
    "    \"batch_size\":            BATCH_SIZE,\n",
    "    \"epochs\":                EPOCHS,\n",
    "    \"encoder_trainable\":     ENCODER_TRAINABLE,\n",
    "    \"history\":               history.history   # contiene loss & metriche per epoca\n",
    "}\n",
    "\n",
    "with open(os.path.join(save_path, 'training_metadata_roberta_custom.json'), 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"Saved model + tokenizer + metadata in {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
