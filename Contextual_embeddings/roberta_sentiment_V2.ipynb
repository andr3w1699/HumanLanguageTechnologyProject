{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3d1942",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install gdown transformers datasets tensorflow scikit-learn tf-keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c78b836",
   "metadata": {},
   "source": [
    "## Dataset loading options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dee970",
   "metadata": {},
   "source": [
    "From Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf067321",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = \"0Bz8a_Dbh9QhbZVhsUnRWRDhETzA\"\n",
    "output_name = 'amazon_review_full_csv.tar.gz'\n",
    "!gdown --fuzzy https://drive.google.com/uc?id={file_id} -O {output_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea5673f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "with tarfile.open(output_name, \"r:gz\") as tar:\n",
    "    tar.extractall(\"Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef4ca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -R Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e61bd72",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ce21f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "import tf_keras as keras \n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "import numpy as np\n",
    "from google.colab import drive\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717a014f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive.mount(\"/content/drive\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be7c556",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "gpu_name = None\n",
    "if gpus:\n",
    "    details = tf.config.experimental.get_device_details(gpus[0])\n",
    "    gpu_name = details.get('device_name', gpus[0].name)\n",
    "else:\n",
    "    gpu_name = 'CPU'\n",
    "\n",
    "print(gpu_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873a888d",
   "metadata": {},
   "source": [
    "## Model settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dd8615",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME    = \"roberta-base\"\n",
    "BATCH_SIZE    = 32\n",
    "EPOCHS        = 5\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_LABELS    = 2\n",
    "RANDOM_STATE = 42\n",
    "BASE_DIR_STORAGE = '/content/drive/MyDrive/HLT_models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde2bb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_filename = \"./Dataset/amazon_review_full_csv/train.csv\"\n",
    "test_data_filename = \"./Dataset/amazon_review_full_csv/test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4845f464",
   "metadata": {},
   "source": [
    "## Utilities Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0cff0a",
   "metadata": {},
   "source": [
    "### Data Loading and Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecb3724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_extract(file_id: str, output_name: str, extract_dir: str):\n",
    "    \n",
    "    os.system(f\"gdown --fuzzy https://drive.google.com/uc?id={file_id} -O {output_name}\")\n",
    "    with tarfile.open(output_name, \"r:gz\") as tar:\n",
    "        tar.extractall(extract_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5194f57d",
   "metadata": {},
   "source": [
    "### Dataframe Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa05c950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataframe(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Legge un CSV con colonne [label, title, text] e rimuove righe malformate.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(\n",
    "        path,\n",
    "        header=None,\n",
    "        names=[\"label\",\"title\",\"text\"],\n",
    "        quotechar='\"', doublequote=True, escapechar='\\\\',\n",
    "        engine='python', encoding='utf-8', on_bad_lines='skip'\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a84e726",
   "metadata": {},
   "source": [
    "Remove NAN and filter by score 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab74b5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.dropna()\n",
    "    df = df[df['label'] != 3]\n",
    "    return df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9248f8bd",
   "metadata": {},
   "source": [
    "### Mapping sentiment for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca0d776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_sentiment(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df['sentiment'] = df['label'].apply(lambda x: 0 if x <= 2 else 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fdc94c",
   "metadata": {},
   "source": [
    "### Text Construction and cleaning\n",
    "Create column 'review' concatenating title and text. Also, apply lowercase and remove newline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1518e68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_reviews(df: pd.DataFrame) -> pd.Series:\n",
    "    reviews = df['title'].fillna('') + ' ' + df['text'].fillna('')\n",
    "    reviews = reviews.str.replace('\\n', ' ', regex=False).str.lower()\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a705e69",
   "metadata": {},
   "source": [
    "### Define Tokenization Class\n",
    "This class contains functions to tokenize text and save encodings to allow performing 'una tantum tokenization'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20b9696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Tokenization & Caching ---\n",
    "class TokenCache:\n",
    "    def __init__(self, max_len: int, cache_dir: str):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "        self.max_len = max_len\n",
    "        os.makedirs(cache_dir, exist_ok=True)\n",
    "        self.cache_dir = cache_dir\n",
    "\n",
    "    def tokenize_and_save(self, texts: list[str], labels, sample_size: str):\n",
    "     \n",
    "        encodings = self.tokenizer(\n",
    "            texts,\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "            padding='do_not_pad',\n",
    "            return_attention_mask=True\n",
    "        )\n",
    "        \n",
    "        os.makedirs(self.cache_dir, exist_ok=True)\n",
    " \n",
    "        # save on disk\n",
    "        np.savez_compressed(\n",
    "            os.path.join(self.cache_dir,f\"train_enc_{MODEL_NAME}_{sample_size}.npz\"),\n",
    "            ids   = np.array(encodings[\"input_ids\"], dtype=object),\n",
    "            attn  = np.array(encodings[\"attention_mask\"], dtype=object),\n",
    "            label = labels\n",
    "        )\n",
    "\n",
    "        npz_path = f\"train_enc_{MODEL_NAME}_{sample_size}.npz\"\n",
    "        # save on temporary session\n",
    "        np.savez_compressed(\n",
    "            f\"train_enc_{MODEL_NAME}_{sample_size}.npz\",\n",
    "            ids   = np.array(encodings[\"input_ids\"], dtype=object),\n",
    "            attn  = np.array(encodings[\"attention_mask\"], dtype=object),\n",
    "            label = labels\n",
    "        )\n",
    "        \n",
    "        return npz_path\n",
    "\n",
    "    def load_encodings(self, npz_path: str):\n",
    "        return np.load(npz_path, allow_pickle=True)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd45c968",
   "metadata": {},
   "source": [
    "### TF Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7b8e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_encodings_to_dataset(d: dict) -> tf.data.Dataset:\n",
    "    \n",
    "    def generator():\n",
    "        for ids, attentions, labels in zip(d[\"ids\"], d[\"attn\"], d[\"label\"]):\n",
    "            yield {\n",
    "                \"input_ids\":     np.array(ids,  dtype=np.int32),\n",
    "                \"attention_mask\": np.array(attentions, dtype=np.int32)\n",
    "        }, np.int32(labels)\n",
    "\n",
    "    raw_ds = tf.data.Dataset.from_generator(\n",
    "        generator,\n",
    "        output_signature=(\n",
    "            {\"input_ids\": tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "             \"attention_mask\": tf.TensorSpec(shape=(None,), dtype=tf.int32)},\n",
    "            tf.TensorSpec(shape=(), dtype=tf.int32)\n",
    "        )\n",
    "    )\n",
    "    return raw_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2a0c2f",
   "metadata": {},
   "source": [
    "### Manage Dynamic padding, batching and prefetch\n",
    "The following function wraps two key steps into one reusable pipeline stage:\n",
    "1. padded_batch(...)\n",
    "\t- Groups elements into batches of size BATCH_SIZE\n",
    "\t- Dynamically pads each batch’s input_ids and attention_mask to the length of the longest sequence in that batch\n",
    "2.\t.prefetch(tf.data.AUTOTUNE)\n",
    "\t- Overlaps data preparation and model execution to keep the GPU fed\n",
    "\n",
    "In short: *prepare_dataset* turns a raw dataset of variable‐length examples into an efficient, dynamically‐padded, batched dataset ready for training.\n",
    "\n",
    "Dynamic padding means that, instead of padding every sequence up to a fixed global MAX_LEN, you pad each batch only up to the length of its longest example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceb570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_dataset(ds: tf.data.Dataset, pad_token_id: int, shuffle_buffer: int = None, repeat: bool = False) -> tf.data.Dataset:\n",
    "  \n",
    "    if shuffle_buffer:\n",
    "        ds = ds.shuffle(buffer_size=shuffle_buffer, seed=RANDOM_STATE)\n",
    "        \n",
    "    ds = ds.padded_batch(\n",
    "        BATCH_SIZE,\n",
    "        padded_shapes=({\"input_ids\": [None], \"attention_mask\": [None]}, []),\n",
    "        padding_values=({\"input_ids\": pad_token_id, \"attention_mask\": 0}, 0)\n",
    "    )\n",
    "    \n",
    "    # in train set, during training without repeat, train set emits all batches only one time\n",
    "    # if steps_for_epochs > real batches -> input ran out of data\n",
    "    # with epochs > 1, at the second epoch there is nothing to read \n",
    "    if repeat:\n",
    "        ds = ds.repeat()\n",
    "        \n",
    "    return ds.prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a0c73c",
   "metadata": {},
   "source": [
    "## Training set preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eabf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = load_dataframe(path=train_data_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59841d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7064aa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d9297f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c242ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc5dc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = clean_dataframe(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d248e54",
   "metadata": {},
   "source": [
    "### Experiment with a subset of 30k samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52368340",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 20_000\n",
    "BASE_DIR_STORAGE = os.path.join(BASE_DIR_STORAGE, f\"{MODEL_NAME}_{SAMPLE_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2662f739",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, _ = train_test_split(\n",
    "    df_train,\n",
    "    train_size=SAMPLE_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=df_train['label']\n",
    ")\n",
    "print(f\"Train size: {len(df_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4e2586",
   "metadata": {},
   "source": [
    "Let's check whether classes are balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f6d339",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462e26a6",
   "metadata": {},
   "source": [
    "### Training set sentiment mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e86b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = map_sentiment(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909a29a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = build_reviews(df_train)\n",
    "labels = df_train['sentiment'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b628fb79",
   "metadata": {},
   "source": [
    "### Setting Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f014aabd",
   "metadata": {},
   "source": [
    "This approach uses the same tokenizer used during the model `MODEL_NAME` pretraining. This allow to preserve the context and language semantics.\n",
    "\n",
    "`AutoTokenizer` is able to infer automatically the model used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a21e6a5",
   "metadata": {},
   "source": [
    "### Analyze tokens distribution to choose the best trade-off for MAX_LEN.\n",
    "The idea is to use the 95th percentile to reduce padding and truncate only outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debb5174",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(train_samples)\n",
    "\n",
    "if N < 10_000:\n",
    "    n_samples = N\n",
    "elif N < 100_000:\n",
    "    n_samples = min(N, 5000)\n",
    "else:\n",
    "    n_samples = min(N, 10_000)\n",
    "\n",
    "\n",
    "#  n_samples are good enough to get a stable estimation of tokens distribution\n",
    "sample_texts = train_samples.sample(n=n_samples, random_state=RANDOM_STATE).tolist()\n",
    "\n",
    "# Tokenize only for analysis (no padding required)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "token_lens = [len(tokenizer.tokenize(t)) for t in sample_texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee431e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(token_lens, bins=50)\n",
    "plt.title(\"Distribution length per token\")\n",
    "plt.xlabel(\"Token per review\")\n",
    "plt.ylabel(\"Frequence\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3189bc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Token length stats:\")\n",
    "print(f\"Mean: {np.mean(token_lens):.1f}\")\n",
    "print(f\"95th percentile: {np.percentile(token_lens, 95):.0f}\")\n",
    "print(f\"Max: {np.max(token_lens)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee495c7",
   "metadata": {},
   "source": [
    "The 95th percentile of tokenized length is around ~200, meaning that 95% of the reviews are shorter than this threshold.\n",
    "\n",
    "To balance memory efficiency and minimize information loss, we set `MAX_LEN = 205`:\n",
    "- This truncates only the top 5% longest reviews (outliers).\n",
    "- It reduces unnecessary padding for the remaining 95% of the data.\n",
    "- It ensures consistent input size for the model without significant loss of content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c67aabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b970dc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537013cb",
   "metadata": {},
   "source": [
    "### Una Tantum tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d96fb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = TokenCache(max_len=MAX_LEN, cache_dir= \"/content/drive/MyDrive/Tokenization_cache\")\n",
    "npz_file = cache.tokenize_and_save(texts=train_samples.tolist(), labels=labels, sample_size=SAMPLE_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083a36c2",
   "metadata": {},
   "source": [
    "Load encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b0040d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings = cache.load_encodings(npz_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a106fc",
   "metadata": {},
   "source": [
    "Create raw tf.data.Dataset from dictionary numpy of {input_ids, attention_mask, label}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a71153",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ds  = from_encodings_to_dataset(encodings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12dae0b",
   "metadata": {},
   "source": [
    "### Split raw Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b41bb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(encodings['label'])\n",
    "int_test_size = int(0.3 * N)\n",
    "val_size  = int(0.2 * N)\n",
    "train_size = N - int_test_size - val_size\n",
    "\n",
    "print(\"Train size:\", train_size)\n",
    "print(\"Val   size:\", val_size)\n",
    "print(\"Test  size:\", int_test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377a0d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_shuffled = raw_ds.shuffle(buffer_size=N, seed=RANDOM_STATE, reshuffle_each_iteration=False)\n",
    "test_ds  = ds_shuffled.take(int_test_size)\n",
    "reminder     = ds_shuffled.skip(int_test_size)\n",
    "val_ds   = reminder.take(val_size)\n",
    "train_ds = reminder.skip(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc05e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_id = cache.tokenizer.pad_token_id\n",
    "# For train shuffle for each epoch and repeat\n",
    "train = prepare_dataset(train_ds, pad_id, shuffle_buffer=train_size, repeat=True)\n",
    "val   = prepare_dataset(val_ds, pad_id)\n",
    "internal_test  = prepare_dataset(test_ds, pad_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90ace47",
   "metadata": {},
   "source": [
    "### Checking for Overlap Between Train, Validation, and Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e497c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use a sample of 1000 to check statistically whether the 3 sets have any intersections\n",
    "def sample_hashes(ds, n=1000):\n",
    "    h = set()\n",
    "    for ex, _ in ds.take(n):\n",
    "        h.add(hash(ex[\"input_ids\"].numpy().tobytes()))\n",
    "    return h\n",
    "\n",
    "h_tr = sample_hashes(train)\n",
    "h_va = sample_hashes(val)\n",
    "h_te = sample_hashes(internal_test)\n",
    "\n",
    "print(\"Intersections between Train and Val  :\", len(h_tr & h_va))\n",
    "print(\"Intersection between Train and Test :\", len(h_tr & h_te))\n",
    "print(\"Intersections between Val and Test :\", len(h_va & h_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c21503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "steps_per_epoch   = math.ceil(train_size / BATCH_SIZE)\n",
    "validation_steps  = math.ceil(val_size   / BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb1d4d0",
   "metadata": {},
   "source": [
    "## Choose whether retrain encoder or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91e1020",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER_TRAINABLE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073f939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79de20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFRobertaModel\n",
    "encoder = TFRobertaModel.from_pretrained(MODEL_NAME)\n",
    "encoder.trainable = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab358c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids      = keras.Input(shape=(None,), dtype=\"int32\", name=\"input_ids\")\n",
    "attention_mask = keras.Input(shape=(None,), dtype=\"int32\", name=\"attention_mask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab74025",
   "metadata": {},
   "source": [
    "Link to pretrained encoders info: https://huggingface.co/transformers/v2.4.0/pretrained_models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee74f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# executed for each batch\n",
    "# here roberta converts input_ids into embedding vectors (batch_size, seq_len, hidden_size) where hidden_size = 768 for roberta-base.\n",
    "encoder_outputs = encoder({'input_ids': input_ids, 'attention_mask': attention_mask}, training = True)\n",
    "pooled_output = encoder_outputs.pooler_output\n",
    "\n",
    "# last hidden state is a tensor (batch_size, seq_len, hidden_size) containing the contextual representation of each token.\n",
    "# cls is used to represent the entire sentence\n",
    "# hidden_states = encoder_outputs.last_hidden_state\n",
    "# cls_token = hidden_states[:, 0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272f613b",
   "metadata": {},
   "source": [
    "### Building Classification Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccf0400",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = keras.layers.Dense(256, activation='relu', name='dense_relu')(pooled_output)\n",
    "x = keras.layers.Dropout(0.3)(x)\n",
    "x = keras.layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "\n",
    "logits = keras.layers.Dense(1, name='logits')(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec71351",
   "metadata": {},
   "source": [
    "### Entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324b696e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=[input_ids, attention_mask], outputs=logits)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e997dfb",
   "metadata": {},
   "source": [
    "Check that encoder parameters are not retrainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66be73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(f\"{layer.name:25s}  trainable={layer.trainable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37d8c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_opt = keras.optimizers.AdamW(           # da tensorflow-addons\n",
    "    learning_rate = LEARNING_RATE,\n",
    "    weight_decay  = 1e-2,\n",
    "    epsilon       = 1e-8,\n",
    "    clipnorm      = 1.0,\n",
    "\n",
    ")\n",
    "\n",
    "optimizer = keras.mixed_precision.LossScaleOptimizer(base_opt)\n",
    "loss= keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[keras.metrics.BinaryAccuracy(name=\"accuracy\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e22fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2154dccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',        \n",
    "    patience=2,                \n",
    "    restore_best_weights=True, \n",
    "    verbose=1                 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f0e52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train,\n",
    "    validation_data= val,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stop] ,\n",
    "    validation_steps=validation_steps,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533dd4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "elapsed = end_time - start_time\n",
    "\n",
    "print(f\"Total training time: {elapsed:.1f} s ({elapsed/60:.2f} min)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa9be29",
   "metadata": {},
   "source": [
    "### Training History plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c340729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Estrai le liste di loss dal history\n",
    "train_loss = history.history['loss']\n",
    "val_loss   = history.history['val_loss']\n",
    "epochs     = range(1, len(train_loss) + 1)\n",
    "\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc   = history.history['val_accuracy']\n",
    "\n",
    "\n",
    "# Disegna il plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(epochs, train_loss, marker='o', label='Train Loss')\n",
    "plt.plot(epochs, val_loss,   marker='o', label='Validation Loss')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.xticks(epochs)           # mostra tutte le epoche sull'asse x\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(epochs, train_acc, marker='o', label='Train Accuracy')\n",
    "plt.plot(epochs, val_acc,   marker='o', label='Validation Accuracy')\n",
    "plt.title('Training vs Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(epochs)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9cc48b",
   "metadata": {},
   "source": [
    "## Model evaluation with Internal test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81906cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.concatenate([y for x, y in internal_test], axis=0)\n",
    "\n",
    "pred_logits = model.predict(internal_test)\n",
    "pred_probs  = tf.sigmoid(pred_logits).numpy().ravel()\n",
    "pred_labels = (pred_probs >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd071288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "accuracy = accuracy_score(y_true, pred_labels)\n",
    "precision = precision_score(y_true, pred_labels)\n",
    "recall = recall_score(y_true, pred_labels)\n",
    "f1 = f1_score(y_true, pred_labels)\n",
    "cm = confusion_matrix(y_true, pred_labels)\n",
    "\n",
    "# Display metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db012222",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514e66ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "conf_matrix = confusion_matrix(y_true, pred_labels)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\n",
    "disp.plot(ax=ax)\n",
    "ax.set_title(\"Confusion Matrix on Internal Test Set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e3d9d4",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64d5ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(BASE_DIR_STORAGE, exist_ok=True)\n",
    "\n",
    "file = os.path.join(BASE_DIR_STORAGE, f'roberta_{SAMPLE_SIZE}.keras')\n",
    "\n",
    "\n",
    "model.save(file)\n",
    "tokenizer.save_pretrained(BASE_DIR_STORAGE)\n",
    "\n",
    "metadata = {\n",
    "    \"timestamp\":          time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"total_training_time_s\": round(elapsed, 1),\n",
    "    \"num_samples\":           SAMPLE_SIZE,\n",
    "    \"train_size\":            train_size,\n",
    "    \"val_size\":              val_size,\n",
    "    \"internal_test_size\":    int_test_size,\n",
    "    \"batch_size\":            BATCH_SIZE,\n",
    "    \"epochs\":                EPOCHS,\n",
    "    \"encoder_trainable\":     ENCODER_TRAINABLE,\n",
    "    \"history\":               history.history,  \n",
    "    \"gpu\": gpu_name,\n",
    "    \"internal_test_accuracy\": accuracy,\n",
    "    \n",
    "}\n",
    "\n",
    "with open(os.path.join(BASE_DIR_STORAGE, f'training_metadata_roberta_{SAMPLE_SIZE}.json'), 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"Saved model + tokenizer + metadata in {BASE_DIR_STORAGE}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
